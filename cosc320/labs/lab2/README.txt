Florent Dondjeu Tschoufack
COSC 320
Lab 2
Feb 13, 2020

(a) the theoretical time complexity for my quicksort was:
	best case O(n^2) and worst case O(n^2)
	the theoritical time complexity for my mergesort was:
	best case O(nlogn) and wost case O(nlogn)

(b) For quicksort the number of element and the time are directly proportional
	along with my merge sort as well. The size of the element has no effect 
	on the sorts.

(c) For quicksort, my average case performed better than both best and worst case
	with what appears to be O(n) according to my graph. For merge sort, the worst
	and best case were fairly close together. I was able to sort 1 million elements with merge sort in a short period unlike quicksort.

(d) I feel my observation does not confirm the different in the best and worst 		case because I feel as if my data is incorrect due to the average case being 
	far better then the other two previuos cases. Merge sort in the other hands handle best and worst case significanly better than quicksort.

(e) Mergesort is far superior than bubble sort. I feel as if quicksort should not
	be O(n^2), because we are not looking back at every single elements twice unlike bubble sort(at least for best case).

(f) I worked on this lab very late, so I could have added more comments for 		future references. I also was not able to figure out how to count the number
	of swaps since both sorts are recurvsive. This code could be used to better undestand how nlogn sorts operate and the complex idea behind the,.
	